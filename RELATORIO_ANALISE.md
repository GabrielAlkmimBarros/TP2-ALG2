# Relat√≥rio de An√°lise Experimental
## Compara√ß√£o de Algoritmos de Clustering: K-Centers

**Disciplina:** Algoritmos 2 - UFMG  
**Data:** 28 de Novembro de 2025  
**Experimento:** Avalia√ß√£o Comparativa de Algoritmos de Agrupamento (Clustering)

---

## Sum√°rio

1. [Introdu√ß√£o](#1-introdu√ß√£o)
2. [Metodologia Experimental](#2-metodologia-experimental)
3. [Descri√ß√£o dos Datasets](#3-descri√ß√£o-dos-datasets)
4. [An√°lise de Sensibilidade do Par√¢metro Œ¥](#4-an√°lise-de-sensibilidade-do-par√¢metro-Œ¥)
5. [Compara√ß√£o de Desempenho Global](#5-compara√ß√£o-de-desempenho-global)
6. [Impacto da Geometria dos Dados](#6-impacto-da-geometria-dos-dados)
7. [An√°lise de Escalabilidade](#7-an√°lise-de-escalabilidade)
8. [Heatmap de Performance](#8-heatmap-de-performance)
9. [Compara√ß√£o de M√©tricas de Dist√¢ncia](#9-compara√ß√£o-de-m√©tricas-de-dist√¢ncia)
10. [Compara√ß√£o por Tipo de Dataset](#10-compara√ß√£o-por-tipo-de-dataset)
11. [Casos Espec√≠ficos de Sucesso](#11-casos-espec√≠ficos-de-sucesso)
12. [Conclus√µes](#12-conclus√µes)
13. [Refer√™ncias das Figuras](#13-refer√™ncias-das-figuras)

---

## 1. Introdu√ß√£o

Este relat√≥rio apresenta uma an√°lise experimental completa comparando tr√™s algoritmos de clustering:

| Algoritmo | Descri√ß√£o | Complexidade |
|-----------|-----------|--------------|
| **K-Means** | Algoritmo iterativo de Lloyd (sklearn) | O(n¬∑k¬∑i¬∑d) |
| **MaxMin** | Algoritmo guloso 2-aproximado para k-centers | O(n¬∑k) |
| **Refinement** | Busca bin√°ria no raio com verifica√ß√£o | O(n¬∑k¬∑log(Œî)) |

### Objetivos do Experimento

1. Avaliar a qualidade do agrupamento usando **Adjusted Rand Index (ARI)** e **Silhouette Score**
2. Comparar o tempo de execu√ß√£o entre implementa√ß√µes otimizadas (C/Cython) e Python puro
3. Analisar o impacto de diferentes m√©tricas de dist√¢ncia
4. Investigar a sensibilidade do algoritmo Refinement ao par√¢metro Œ¥

---

## 2. Metodologia Experimental

### 2.1 Configura√ß√£o do Experimento

| Par√¢metro | Valor |
|-----------|-------|
| N√∫mero de execu√ß√µes (N_RUNS) | 15 |
| Valores de Œ¥ testados | 0.01, 0.05, 0.10, 0.15, 0.25 |
| Total de datasets | 51 |
| Total de registros gerados | 19.125 |

### 2.2 M√©tricas de Dist√¢ncia Avaliadas

| M√©trica | F√≥rmula | Implementa√ß√£o |
|---------|---------|---------------|
| Euclidiana | $\sqrt{\sum_{i=1}^{d}(x_i - y_i)^2}$ | sklearn (otimizada) |
| Minkowski-L1 (Manhattan) | $\sum_{i=1}^{d}\|x_i - y_i\|$ | Python |
| Minkowski-L2 | $\sqrt{\sum_{i=1}^{d}(x_i - y_i)^2}$ | Python |
| Minkowski-L3 | $\sqrt[3]{\sum_{i=1}^{d}\|x_i - y_i\|^3}$ | Python |
| Mahalanobis | $\sqrt{(x-y)^T \Sigma^{-1} (x-y)}$ | Python |

### 2.3 M√©tricas de Avalia√ß√£o

- **Adjusted Rand Index (ARI)**: Mede a concord√¢ncia entre clusters preditos e ground truth, ajustado para chance. Varia de -1 a 1, onde 1 indica concord√¢ncia perfeita.

- **Silhouette Score**: Mede a coes√£o intra-cluster e separa√ß√£o inter-cluster. Varia de -1 a 1, onde valores altos indicam clusters bem definidos.

- **Tempo de Execu√ß√£o**: Medido em segundos usando `time.perf_counter()`.

---

## 3. Descri√ß√£o dos Datasets

### 3.1 Distribui√ß√£o por Tipo

| Tipo | Quantidade | Descri√ß√£o |
|------|------------|-----------|
| Sint√©tico (Scikit-Learn) | 30 | Blobs, Anisotropic, Circles, Moons, etc. |
| Sint√©tico (Normal Multivariada) | 10 | Clusters com covari√¢ncias personalizadas |
| Real (UCI) | 11 | Datasets reais do UCI Repository |
| **Total** | **51** | |

### 3.2 Datasets Reais (UCI)

| Dataset | Amostras | Dimens√µes | k (clusters) |
|---------|----------|-----------|--------------|
| UCI_Banknote | 1.372 | 4 | 2 |
| UCI_OptDigits | 5.620 | 64 | 10 |
| UCI_WineRed | 1.599 | 11 | 6 |
| UCI_WineWhite | 4.898 | 11 | 7 |
| UCI_Bankruptcy | 6.819 | 95 | 2 |
| UCI_SECOM | 1.567 | 590 | 2 |
| UCI_DrugConsumption | 1.885 | 12 | 7 |
| UCI_MyocardialInfarction | 1.700 | 123 | 8 |
| UCI_Obesity | 2.111 | 16 | 7 |
| UCI_Cardiotocography | 2.126 | 36 | 3 |
| UCI_BEED_EEG | 8.000 | 16 | 4 |

### 3.3 Geometrias dos Datasets Sint√©ticos

| Geometria | Descri√ß√£o | Desafio para Clustering |
|-----------|-----------|------------------------|
| Blobs (Esf√©rico) | Clusters esf√©ricos bem separados | Baixo |
| Anisotropic (El√≠ptico) | Clusters alongados/rotacionados | M√©dio |
| Vari√¢ncia Variada | Clusters com tamanhos diferentes | M√©dio |
| N√£o-Convexo (Circles, Moons) | Formas n√£o-lineares | Alto |
| Normal Multivariada | Covari√¢ncias customizadas | M√©dio-Alto |

---

## 4. An√°lise de Sensibilidade do Par√¢metro Œ¥

**Figura:** `fig1_sensitivity_analysis.png`

### 4.1 Resultados

| Œ¥ (Delta Ratio) | ARI M√©dio | Desvio Padr√£o | Tempo M√©dio (s) | N Amostras |
|-----------------|-----------|---------------|-----------------|------------|
| 0.01 | **0.4453** | 0.3637 | 0.00159 | 2.400 |
| 0.05 | 0.4426 | 0.3644 | 0.00127 | 2.385 |
| 0.10 | 0.4371 | 0.3629 | 0.00109 | 2.325 |
| 0.15 | 0.4330 | 0.3426 | 0.00090 | 2.085 |
| 0.25 | 0.4063 | 0.3141 | 0.00064 | 1.845 |

### 4.2 An√°lise

O gr√°fico demonstra claramente o **trade-off entre qualidade e efici√™ncia** no algoritmo Refinement:

1. **Rela√ß√£o Inversa Œ¥ vs ARI**: 
   - Intervalos menores (Œ¥=0.01) produzem melhor qualidade (ARI = 0.445)
   - Intervalos maiores (Œ¥=0.25) t√™m qualidade reduzida (ARI = 0.406)
   - **Diferen√ßa total: ~10% de perda em ARI**

2. **Rela√ß√£o Direta Œ¥ vs Tempo**:
   - Œ¥=0.01 leva 2.5x mais tempo que Œ¥=0.25
   - O tempo segue aproximadamente O(log(1/Œ¥)) devido √† busca bin√°ria

3. **Recomenda√ß√£o Pr√°tica**:
   - **Œ¥ = 0.05** oferece o melhor compromisso (ARI = 0.443, apenas 0.5% abaixo do √≥timo, mas 20% mais r√°pido)
   - Para aplica√ß√µes cr√≠ticas: usar Œ¥ = 0.01
   - Para prototipagem r√°pida: usar Œ¥ = 0.15 ou 0.25

### 4.3 Interpreta√ß√£o Te√≥rica

O par√¢metro Œ¥ controla a largura do intervalo de busca bin√°ria. Um intervalo mais estreito (Œ¥ pequeno) permite encontrar um raio mais pr√≥ximo do √≥timo, mas requer mais itera√ß√µes de busca. A garantia te√≥rica √© que o raio encontrado est√° dentro de (1+Œ¥) do √≥timo.

---

## 5. Compara√ß√£o de Desempenho Global

**Figura:** `fig2_boxplot_comparison.png`

### 5.1 Estat√≠sticas Globais

| Algoritmo | ARI M√©dio | ARI Desvio | Silhouette | Tempo (s) |
|-----------|-----------|------------|------------|-----------|
| **KMeans** | **0.4729** | 0.4020 | 0.4610 | 0.0093 |
| Refinement | 0.3552 | 0.3568 | **0.4636** | 0.0055 |
| MaxMin | 0.3196 | 0.3430 | 0.4339 | **0.0002** |

### 5.2 An√°lise por M√©trica de Dist√¢ncia

| M√©trica | Algoritmo | ARI M√©dio | ARI Mediana |
|---------|-----------|-----------|-------------|
| Euclidiana (L2) | KMeans | **0.4729** | 0.4933 |
| Euclidiana (L2) | MaxMin | 0.3365 | 0.2520 |
| Euclidiana (L2) | Refinement | 0.3792 | 0.4297 |
| Mahalanobis | MaxMin | 0.2564 | 0.0417 |
| Mahalanobis | Refinement | 0.2971 | 0.0825 |
| Manhattan (L1) | MaxMin | 0.3485 | 0.4216 |
| Manhattan (L1) | Refinement | 0.3712 | 0.3884 |

### 5.3 An√°lise dos Boxplots

Os boxplots revelam caracter√≠sticas importantes:

1. **Variabilidade (Tamanho das Caixas)**:
   - KMeans tem maior variabilidade (caixa maior), indicando desempenho inconsistente entre datasets
   - MaxMin e Refinement t√™m caixas menores, sugerindo maior estabilidade

2. **Outliers**:
   - Todos os algoritmos apresentam outliers negativos (datasets dif√≠ceis)
   - KMeans tem mais outliers positivos (datasets onde brilha)

3. **Mediana vs M√©dia**:
   - KMeans: Mediana (0.49) > M√©dia (0.47) ‚Üí distribui√ß√£o assim√©trica √† esquerda
   - MaxMin: Mediana (0.25) < M√©dia (0.32) ‚Üí alguns casos muito bons puxam a m√©dia

4. **Por M√©trica**:
   - **Euclidiana**: Melhor desempenho geral para todos os algoritmos
   - **Mahalanobis**: Pior desempenho, especialmente para MaxMin (mediana = 0.04)
   - **Manhattan**: Performance intermedi√°ria, mais est√°vel que Mahalanobis

---

## 6. Impacto da Geometria dos Dados

**Figura:** `fig3_geometry_impact.png`

### 6.1 Compara√ß√£o Euclidiana vs Mahalanobis por Geometria

| Geometria | Euclidiana | Mahalanobis | Œî Absoluta | Vencedor |
|-----------|------------|-------------|------------|----------|
| Anisotropic (El√≠ptico) | **0.725** | 0.559 | +0.166 | Euclidiana |
| Blobs (Esf√©rico) | **0.629** | 0.365 | +0.264 | Euclidiana |
| Normal Multivariada | **0.606** | 0.591 | +0.015 | Euclidiana |
| N√£o-Convexo | **0.241** | 0.108 | +0.133 | Euclidiana |

### 6.2 An√°lise Detalhada

**Resultado Surpreendente:** Contrariando a hip√≥tese te√≥rica, a dist√¢ncia **Euclidiana superou Mahalanobis** em todos os cen√°rios testados.

#### Hip√≥tese Inicial (N√£o Confirmada):
> "Mahalanobis deveria ser melhor para clusters el√≠pticos porque considera a covari√¢ncia dos dados"

#### Poss√≠veis Explica√ß√µes para o Resultado:

1. **Instabilidade Num√©rica**:
   - A invers√£o da matriz de covari√¢ncia (Œ£‚Åª¬π) pode ser mal-condicionada
   - Pequenas perturba√ß√µes nos dados causam grandes varia√ß√µes na m√©trica
   
2. **Covari√¢ncia Global vs Local**:
   - A implementa√ß√£o usa covari√¢ncia global (todos os pontos)
   - Clusters t√™m covari√¢ncias diferentes, a m√©dia global n√£o representa bem nenhum

3. **Efeito de Outliers**:
   - Outliers distorcem a matriz de covari√¢ncia estimada
   - Datasets reais t√™m mais ru√≠do que afeta a estimativa

4. **Necessidade de Regulariza√ß√£o**:
   - T√©cnicas como *shrinkage* (Ledoit-Wolf) poderiam estabilizar a estimativa
   - A implementa√ß√£o atual n√£o usa regulariza√ß√£o

### 6.3 Casos por Geometria

**Clusters El√≠pticos (Anisotropic):**
- Teoricamente o melhor caso para Mahalanobis
- Na pr√°tica: Euclidiana √© 30% melhor
- **Causa prov√°vel**: Covari√¢ncia global mistura as orienta√ß√µes de diferentes clusters

**Clusters Esf√©ricos (Blobs):**
- Euclidiana √© naturalmente adequada
- Mahalanobis perde 72% de desempenho
- **Causa prov√°vel**: Covari√¢ncia adiciona complexidade desnecess√°ria

**Dados N√£o-Convexos (Circles, Moons):**
- Ambas as m√©tricas falham (ARI < 0.25)
- Euclidiana ainda √© 123% melhor que Mahalanobis
- **Causa**: Nenhuma m√©trica de dist√¢ncia pontual captura estruturas n√£o-lineares

---

## 7. An√°lise de Escalabilidade

**Figura:** `fig4_scalability.png`

### 7.1 Tempo de Execu√ß√£o por Algoritmo

| Algoritmo | Tempo M√≠n | Tempo M√©dio | Tempo M√°x | Fator vs KMeans |
|-----------|-----------|-------------|-----------|-----------------|
| **MaxMin** | 0.00002s | **0.0002s** | 0.006s | **46x mais r√°pido** |
| Refinement | 0.0003s | 0.0058s | 0.181s | 1.6x mais r√°pido |
| KMeans | 0.0039s | 0.0093s | 0.248s | (baseline) |

### 7.2 An√°lise do Gr√°fico de Barras Horizontais

O gr√°fico mostra os 25 datasets mais lentos, ordenados pelo tempo do KMeans:

1. **Datasets Mais Lentos**:
   - UCI_OptDigits (5620 √ó 64): ~0.15s para KMeans
   - UCI_BEED_EEG (8000 √ó 16): ~0.12s para KMeans
   - UCI_Bankruptcy (6819 √ó 95): ~0.10s para Refinement

2. **Padr√£o de Escalonamento**:
   - MaxMin mant√©m tempo consistentemente baixo (barras curtas)
   - Refinement escala pior que MaxMin em alta dimens√£o
   - KMeans escala linearmente com n√ód

3. **Impacto da Dimensionalidade**:
   - UCI_SECOM (590 dimens√µes) √© desafiador para todos
   - Mahalanobis sofre mais com alta dimens√£o (invers√£o de matriz 590√ó590)

### 7.3 Complexidade Te√≥rica vs Pr√°tica

| Algoritmo | Complexidade Te√≥rica | Comportamento Observado |
|-----------|---------------------|------------------------|
| KMeans | O(n¬∑k¬∑i¬∑d) | Escala bem, mas constante alta (C otimizado) |
| MaxMin | O(n¬∑k) | Extremamente r√°pido, constante baixa |
| Refinement | O(n¬∑k¬∑log(Œî/Œ¥)) | Mais lento que MaxMin devido ao fator log |

### 7.4 Recomenda√ß√µes de Uso

| Cen√°rio | Algoritmo Recomendado | Justificativa |
|---------|----------------------|---------------|
| Prot√≥tipo r√°pido | **MaxMin** | 46x mais r√°pido, qualidade razo√°vel |
| Produ√ß√£o (qualidade) | **KMeans** | Melhor ARI, implementa√ß√£o otimizada |
| Streaming/Online | **MaxMin** | O(n¬∑k) por ponto, sem itera√ß√µes |
| Garantias te√≥ricas | **Refinement** | 2-aproxima√ß√£o garantida com Œ¥ control√°vel |

---

## 8. Heatmap de Performance

**Figura:** `fig5_heatmap_performance.png`

### 8.1 Interpreta√ß√£o do Mapa de Calor

O heatmap apresenta o ARI m√©dio para cada combina√ß√£o (Dataset √ó Algoritmo), usando escala de cores:
- üü¢ **Verde escuro**: ARI > 0.7 (excelente)
- üü° **Amarelo**: ARI ‚âà 0.3-0.5 (moderado)
- üî¥ **Vermelho**: ARI < 0.1 (ruim)

### 8.2 Padr√µes Identificados

**Datasets com √ìtimo Desempenho (Verde) para Todos:**
- SKL_Blobs_* (todos os 5)
- SKL_Anisotropic_* (todos os 5)
- MultiVar_* (8 de 10)

**Datasets Desafiadores (Vermelho) para Todos:**
- SKL_NoisyCircles_* (ARI ‚âà 0)
- UCI_SECOM (alta dimens√£o, ru√≠do)
- UCI_Bankruptcy (classes desbalanceadas)

**Datasets com Diverg√™ncia (KMeans muito melhor):**
- UCI_OptDigits: KMeans = 0.52, MaxMin/Refinement = 0.01
- UCI_Cardiotocography: KMeans = 0.23, outros < 0.03

**Datasets com Converg√™ncia (Algoritmos similares):**
- SKL_Blobs_*: Todos > 0.9
- MultiVar_Spherical_*: Todos > 0.8

### 8.3 An√°lise de Clusters no Heatmap

Agrupando datasets por padr√£o:

| Cluster | Datasets | Caracter√≠stica | Melhor Algoritmo |
|---------|----------|----------------|------------------|
| A | Blobs, Aniso | Bem separados, esf√©ricos/el√≠pticos | Todos similares |
| B | Circles, Moons | N√£o-convexos | MaxMin ligeiramente melhor |
| C | UCI alto-dim | Alta dimensionalidade | KMeans muito melhor |
| D | UCI ruidosos | Muito ru√≠do, poucas features | Todos ruins |

---

## 9. Compara√ß√£o de M√©tricas de Dist√¢ncia

**Figura:** `fig6_metric_comparison.png`

### 9.1 Ranking de M√©tricas por ARI

| Ranking | M√©trica | ARI M√©dio | Desvio Padr√£o | N Experimentos |
|---------|---------|-----------|---------------|----------------|
| 1¬∫ | **Euclidiana** | **0.4729** | 0.4020 | 765 |
| 2¬∫ | Minkowski-L2 | 0.3712 | 0.3594 | 4.110 |
| 3¬∫ | Minkowski-L1 | 0.3672 | 0.3523 | 4.305 |
| 4¬∫ | Minkowski-L3 | 0.3655 | 0.3565 | 4.155 |
| 5¬∫ | Mahalanobis | 0.2895 | 0.3437 | 4.110 |

### 9.2 An√°lise Comparativa

**1. Euclidiana vs Minkowski-L2 (Matematicamente Equivalentes)**

Ambas calculam a norma L2, mas:
- Euclidiana (sklearn): Implementada em Cython, usa BLAS
- Minkowski-L2 (nossa): Implementada em Python puro

**Diferen√ßa de 27% no ARI!** Isso sugere que:
- A efici√™ncia computacional permite mais itera√ß√µes no tempo limite
- Opera√ß√µes vetorizadas podem ter melhor precis√£o num√©rica
- O overhead do Python adiciona lat√™ncia que afeta converg√™ncia

**2. Normas Lp (L1, L2, L3) S√£o Praticamente Equivalentes**

| Compara√ß√£o | Diferen√ßa ARI |
|------------|---------------|
| L2 vs L1 | +1.1% |
| L2 vs L3 | +1.6% |
| L1 vs L3 | +0.5% |

**Conclus√£o**: A escolha entre L1, L2, L3 tem impacto marginal. Use L2 por padr√£o.

**3. Mahalanobis √© Consistentemente Pior**

- 22% pior que Minkowski-L2
- 38% pior que Euclidiana nativa

**Causas identificadas:**
1. Instabilidade num√©rica na invers√£o de matriz
2. Covari√¢ncia global inadequada para clusters heterog√™neos
3. Custo computacional maior (O(d¬≤) por dist√¢ncia)

### 9.3 Recomenda√ß√µes

| Situa√ß√£o | M√©trica Recomendada |
|----------|---------------------|
| Uso geral | Euclidiana (sklearn) |
| Features com escalas diferentes | Manhattan (L1) ap√≥s normaliza√ß√£o |
| Dados esparsos | Manhattan (L1) |
| Outliers presentes | Manhattan (L1) |
| Conhecimento pr√©vio de covari√¢ncia | Mahalanobis com regulariza√ß√£o |

---

## 10. Compara√ß√£o por Tipo de Dataset

**Figura:** `fig7_dataset_type_comparison.png`

### 10.1 ARI por Tipo de Dataset

| Tipo | KMeans | MaxMin | Refinement | Gap (KMeans - Melhor outro) |
|------|--------|--------|------------|---------------------------|
| Sint√©tico (MultiVar) | **0.7383** | 0.5978 | 0.5700 | +0.1405 (19%) |
| Sint√©tico (SKL) | **0.5134** | 0.3373 | 0.3835 | +0.1299 (25%) |
| Real (UCI) | **0.1214** | 0.0183 | 0.0171 | +0.1031 (85%) |

### 10.2 Tempo de Execu√ß√£o por Tipo

| Tipo | KMeans | MaxMin | Refinement |
|------|--------|--------|------------|
| Sint√©tico (MultiVar) | 0.0061s | **0.0001s** | 0.0015s |
| Sint√©tico (SKL) | 0.0060s | **0.0001s** | 0.0009s |
| Real (UCI) | 0.0210s | **0.0006s** | 0.0229s |

### 10.3 An√°lise Detalhada

**Gap Crescente em Dados Reais:**

O gr√°fico mostra que a diferen√ßa de desempenho entre KMeans e os outros algoritmos **aumenta dramaticamente** em dados reais:

- Em dados sint√©ticos: KMeans √© ~25% melhor
- Em dados reais: KMeans √© **85% melhor**

**Poss√≠veis Causas:**

1. **Inicializa√ß√£o**:
   - KMeans usa K-Means++ (sklearn), que escolhe centros iniciais otimizados
   - MaxMin come√ßa do ponto mais distante, sem considerar a distribui√ß√£o global

2. **Refinamento Iterativo**:
   - KMeans refina centros iterativamente (Lloyd's algorithm)
   - MaxMin/Refinement s√£o algoritmos de uma passada (greedy)

3. **Natureza dos Dados Reais**:
   - Mais ru√≠do e outliers
   - Classes desbalanceadas
   - Features com correla√ß√µes complexas
   - Clusters n√£o s√£o esf√©ricos ou bem separados

**Efici√™ncia em Dados Reais:**

Apesar do pior ARI, MaxMin √© **35x mais r√°pido** que KMeans em dados UCI. Para aplica√ß√µes onde tempo √© cr√≠tico e uma solu√ß√£o aproximada √© aceit√°vel, MaxMin continua sendo uma boa escolha.

### 10.4 Distribui√ß√£o Visual (Boxplot)

O boxplot √† esquerda mostra:
- **Dados Sint√©ticos**: Distribui√ß√£o mais concentrada, medianas altas
- **Dados Reais**: Distribui√ß√£o espalhada, muitos valores pr√≥ximos de zero

O gr√°fico de barras √† direita confirma:
- Tempo aumenta significativamente para dados UCI (mais amostras, mais dimens√µes)
- Refinement tem tempo compar√°vel ao KMeans em dados reais (Mahalanobis √© custoso)

---

## 11. Casos Espec√≠ficos de Sucesso

### 11.1 Datasets Onde MaxMin/Refinement Superam KMeans

| Dataset | KMeans | MaxMin | Refinement | Melhor Alternativo | Ganho |
|---------|--------|--------|------------|--------------------|-------|
| UCI_Banknote | 0.0131 | 0.0787 | **0.0883** | Refinement | +575% |
| UCI_Bankruptcy | -0.0165 | 0.0019 | **0.0052** | Refinement | ‚Äî |
| SKL_NoisyCircles_5 | -0.0013 | **0.0389** | 0.0199 | MaxMin | ‚Äî |
| SKL_NoisyCircles_4 | -0.0013 | **0.0195** | 0.0100 | MaxMin | ‚Äî |
| SKL_NoisyCircles_2 | -0.0014 | **0.0118** | 0.0040 | MaxMin | ‚Äî |
| SKL_NoisyMoons_3 | 0.4694 | **0.4786** | 0.4496 | MaxMin | +2% |
| SKL_NoisyCircles_1 | -0.0013 | -0.0008 | **0.0015** | Refinement | ‚Äî |
| SKL_NoisyCircles_3 | -0.0013 | **-0.0001** | -0.0009 | MaxMin | ‚Äî |

**Total: 8 datasets (16%)** onde os algoritmos implementados superam KMeans.

### 11.2 An√°lise dos Casos de Sucesso

**Padr√£o Identificado:** MaxMin/Refinement tendem a superar KMeans em:

1. **Dados N√£o-Convexos (Circles)**:
   - KMeans assume clusters esf√©ricos
   - MaxMin escolhe pontos mais distantes, que podem estar nas bordas das estruturas circulares
   - ARI ainda √© baixo para todos, mas MaxMin √© menos negativo

2. **Dados com Estrutura Peculiar (Banknote, Bankruptcy)**:
   - Estes datasets t√™m distribui√ß√µes que n√£o favorecem a converg√™ncia do Lloyd's algorithm
   - A escolha gulosa do MaxMin pode escapar de m√≠nimos locais ruins

3. **Interpreta√ß√£o Cautelosa**:
   - Em todos os casos, os ARIs absolutos ainda s√£o baixos (< 0.1)
   - A "vit√≥ria" √© relativa a um baseline j√° ruim
   - N√£o significa que MaxMin/Refinement s√£o bons nesses datasets, apenas menos ruins

### 11.3 UCI_Banknote: Estudo de Caso

O dataset Banknote merece aten√ß√£o especial:

- **Descri√ß√£o**: Detec√ß√£o de notas falsas (2 classes: genu√≠na/falsa)
- **Features**: 4 medidas de wavelet extra√≠das de imagens
- **Resultado**: Refinement (0.088) >> KMeans (0.013)

**Por que KMeans falhou?**
- As classes n√£o s√£o linearmente separ√°veis em L2
- KMeans converge para um m√≠nimo local ruim
- A inicializa√ß√£o K-Means++ n√£o ajuda neste caso espec√≠fico

**Por que Refinement funcionou melhor?**
- A busca bin√°ria no raio encontra uma cobertura mais equilibrada
- Menos sens√≠vel a m√≠nimos locais por n√£o ser iterativo

---

## 12. Conclus√µes

### 12.1 Resumo dos Principais Achados

| Aspecto | Conclus√£o |
|---------|-----------|
| **Qualidade (ARI)** | KMeans > Refinement > MaxMin na maioria dos casos |
| **Efici√™ncia** | MaxMin √© 46x mais r√°pido que KMeans |
| **Trade-off Œ¥** | Œ¥=0.05 oferece bom compromisso qualidade/tempo |
| **M√©tricas** | Euclidiana (nativa) √© a melhor; Mahalanobis decepcionou |
| **Dados Reais** | Gap de qualidade aumenta; MaxMin ainda √© √∫til por velocidade |
| **Casos Especiais** | MaxMin/Refinement vencem em 16% dos datasets (n√£o-convexos) |

### 12.2 Contribui√ß√µes Te√≥ricas Validadas

1. ‚úÖ **MaxMin √© O(nk)**: Confirmado experimentalmente (tempo constante baixo)
2. ‚úÖ **Refinement oferece garantia 2-aproxima√ß√£o**: Funciona conforme esperado
3. ‚ùå **Mahalanobis para clusters el√≠pticos**: N√£o confirmado sem regulariza√ß√£o
4. ‚úÖ **Trade-off precis√£o/tempo com Œ¥**: Claramente demonstrado

### 12.3 Limita√ß√µes do Estudo

1. **Implementa√ß√£o Python**: MaxMin/Refinement em Python puro, n√£o otimizados
2. **Covari√¢ncia Global**: Mahalanobis usa matriz global, n√£o local
3. **Aus√™ncia de Regulariza√ß√£o**: Pode explicar falha de Mahalanobis
4. **Datasets Limitados**: 51 datasets podem n√£o representar todos os casos

### 12.4 Recomenda√ß√µes Pr√°ticas

| Cen√°rio | Recomenda√ß√£o |
|---------|--------------|
| **Aplica√ß√£o Geral** | Use sklearn.KMeans com Euclidiana |
| **Tempo Cr√≠tico** | Use MaxMin para solu√ß√£o r√°pida 2-aproximada |
| **Garantias Formais** | Use Refinement com Œ¥ apropriado |
| **Dados N√£o-Convexos** | Considere algoritmos espectrais (DBSCAN, Spectral Clustering) |
| **Alta Dimens√£o** | Use PCA antes do clustering; evite Mahalanobis |

### 12.5 Trabalhos Futuros

1. **Otimiza√ß√£o**: Implementar MaxMin/Refinement em Cython ou Numba
2. **Mahalanobis Local**: Usar covari√¢ncia por cluster (EM-like)
3. **Regulariza√ß√£o**: Aplicar Ledoit-Wolf shrinkage na matriz de covari√¢ncia
4. **Mais M√©tricas**: Testar cosseno, correla√ß√£o, DTW para s√©ries temporais
5. **Benchmarks Maiores**: Testar em datasets com milh√µes de pontos

---

## 13. Refer√™ncias das Figuras

| Arquivo | Descri√ß√£o | Se√ß√£o |
|---------|-----------|-------|
| `fig1_sensitivity_analysis.png` | Sensibilidade do par√¢metro Œ¥ | ¬ß4 |
| `fig2_boxplot_comparison.png` | Boxplots de ARI por algoritmo/m√©trica | ¬ß5 |
| `fig3_geometry_impact.png` | Euclidiana vs Mahalanobis por geometria | ¬ß6 |
| `fig4_scalability.png` | Tempo de execu√ß√£o por dataset | ¬ß7 |
| `fig5_heatmap_performance.png` | Heatmap ARI (Dataset √ó Algoritmo) | ¬ß8 |
| `fig6_metric_comparison.png` | Compara√ß√£o de m√©tricas de dist√¢ncia | ¬ß9 |
| `fig7_dataset_type_comparison.png` | Sint√©tico vs Real | ¬ß10 |
| `tabela_resumo.tex` | Tabela LaTeX para artigo IEEE | Ap√™ndice |

---

## Ap√™ndice: Tabela LaTeX para Artigo IEEE

```latex
\begin{table}[htbp]
\centering
\caption{Resumo Comparativo dos Algoritmos de Clustering (M√©dia $\pm$ Desvio Padr√£o)}
\label{tab:resumo_algoritmos}
\begin{tabular}{lccc}
\hline
\textbf{Algoritmo} & \textbf{ARI} & \textbf{Silhouette} & \textbf{Tempo (s)} \\
\hline
KMeans & $0.4729 \pm 0.4020$ & $0.4610 \pm 0.2079$ & $0.0093 \pm 0.0145$ \\
MaxMin & $0.3196 \pm 0.3430$ & $0.4339 \pm 0.1984$ & $0.0002 \pm 0.0004$ \\
Refinement & $0.3552 \pm 0.3568$ & $0.4636 \pm 0.1930$ & $0.0055 \pm 0.0161$ \\
\hline
\end{tabular}
\end{table}
```

---

*Relat√≥rio gerado automaticamente em 28/11/2025*  
*Ferramentas: Python 3.x, Pandas, Matplotlib, Seaborn*
